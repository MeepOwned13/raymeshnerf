{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow importing from src\n",
    "import sys\n",
    "sys.path.insert(0, '../src/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  np.load(\"../data/tiny_nerf_data.npz\")\n",
    "images, c2ws, focal = data[\"images\"], data[\"poses\"], data[\"focal\"]\n",
    "\n",
    "print(\n",
    "    f\"Shapes:\",\n",
    "    f\"Images: {images.shape}\",\n",
    "    f\"C2ws:   {c2ws.shape}\",\n",
    "    f\"Focal:  {focal.shape}\",\n",
    "    sep='\\n  ',\n",
    ")\n",
    "\n",
    "plt.imshow(images[2])\n",
    "plt.title(\"Image at index 2\")\n",
    "\n",
    "print(f\"C2W transform at index 2: \\n\", c2ws[2])\n",
    "\n",
    "print(f\"Focal length: {focal:.4f}\")\n",
    "\n",
    "images = torch.from_numpy(images)\n",
    "c2ws = torch.from_numpy(c2ws)\n",
    "focal = torch.from_numpy(focal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "\n",
    "To be exported into `ROOT_DIR/src/utils/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rays(height, width, intrinsic, c2w):\n",
    "    focal_x = intrinsic[0, 0]\n",
    "    focal_y = intrinsic[1, 1]\n",
    "    # cx and cy handle the misalignement of the principal point with the center of the image\n",
    "    cx = intrinsic[0, 2]\n",
    "    cy = intrinsic[1, 2]\n",
    "\n",
    "    # Index each point on the image, determine ray directions to them\n",
    "    i, j = torch.meshgrid(torch.arange(width, dtype=torch.float32), torch.arange(height, dtype=torch.float32), indexing='xy')\n",
    "    directions = torch.stack((\n",
    "        (i - cx) / focal_x,\n",
    "        -(j - cy) / focal_y,\n",
    "        -torch.ones(i.shape, dtype=torch.float32)  # -1 since ray is cast away from camera\n",
    "    ), -1)\n",
    "\n",
    "    # Transform ray directions to World, origins just need to be broadcasted accordingly\n",
    "    ray_directions = directions @ c2w[:3, :3].T\n",
    "    ray_origins = torch.broadcast_to(c2w[:3, -1], ray_directions.shape)  # c2w last column determines position\n",
    "    \n",
    "    return ray_origins, ray_directions\n",
    "\n",
    "\n",
    "# Test on real data\n",
    "ex_index = 2\n",
    "ex_img = images[ex_index]\n",
    "ex_intr = torch.tensor([\n",
    "    [focal.item(), 0, ex_img.shape[1] // 2],\n",
    "    [0, focal.item(), ex_img.shape[0] // 2],\n",
    "    [0, 0, 1],\n",
    "], dtype=torch.float32)\n",
    "\n",
    "o, d = create_rays(ex_img.shape[0], ex_img.shape[1], ex_intr, c2ws[ex_index])\n",
    "\n",
    "\"\"\"\n",
    "# Test on example data\n",
    "ex_intr = torch.tensor([\n",
    "    [4, 0, 5 // 2],\n",
    "    [0, 4, 5 // 2],\n",
    "    [0, 0, 1],\n",
    "], dtype=torch.float32)\n",
    "\n",
    "ex_c2w = torch.tensor([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 1, 1],\n",
    "    [0, 0, 0, 1],\n",
    "], dtype=torch.float32)\n",
    "\n",
    "o, d = create_rays(5, 5, ex_intr, ex_c2w)\n",
    "\"\"\"\n",
    "\n",
    "print(o.shape, d.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
