{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c66edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow importing from src\n",
    "import sys\n",
    "sys.path.insert(0, '../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb3f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerf import LNeRF\n",
    "from utils.rays import create_rays, render_rays\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "COMPUTE_DEVICE = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    COMPUTE_DEVICE = torch.device('cuda:0')\n",
    "elif torch.mps.is_available():\n",
    "    COMPUTE_DEVICE = torch.device('mps')\n",
    "print(f\"{COMPUTE_DEVICE=}\")\n",
    "\n",
    "float_to_rad = lambda f: torch.deg2rad(torch.tensor(f, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631ac047",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62440382",
   "metadata": {},
   "source": [
    "## Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a05403",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LNeRF.load_from_checkpoint(\n",
    "    \"../lightning_logs/shurtape200x200_decay=1e-06_exp/checkpoints/best_val_psnr_epoch=9.ckpt\",\n",
    "    map_location=COMPUTE_DEVICE,\n",
    "    hparams_file=\"../lightning_logs/shurtape200x200_decay=1e-06_exp/hparams.yaml\"\n",
    ")\n",
    "model.freeze()\n",
    "focal = torch.tensor(model.hparams.focal, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b4e772",
   "metadata": {},
   "source": [
    "## Rendering parameter calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e6c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In accordance with mitsuba's conventions\n",
    "def look_at(radius: float, theta: Tensor, phi: Tensor, target: Tensor = torch.tensor([0,0,0], dtype=torch.float32)):\n",
    "    origin = torch.tensor([\n",
    "        radius * torch.sin(theta) * torch.cos(phi),\n",
    "        radius * torch.sin(theta) * torch.sin(phi),\n",
    "        radius * torch.cos(theta),\n",
    "    ])\n",
    "    \n",
    "    forward = F.normalize(origin - target, p=\"fro\", dim=0)\n",
    "    up = torch.tensor([0, 0, 1], dtype=torch.float32)\n",
    "    right = F.normalize(torch.cross(up, forward, dim=0), p=\"fro\", dim=0)\n",
    "    up = F.normalize(torch.cross(forward, right, dim=0), p=\"fro\", dim=0)\n",
    "\n",
    "    return torch.tensor([\n",
    "        [right[0], up[0], forward[0], origin[0]],\n",
    "        [right[1], up[1], forward[1], origin[1]],\n",
    "        [right[2], up[2], forward[2], origin[2]],\n",
    "        [0, 0, 0, 1],\n",
    "    ])\n",
    "\n",
    "look_at(4, float_to_rad(45), float_to_rad(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ad3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intrinsic(focal: Tensor, size: float):\n",
    "    return torch.tensor([\n",
    "        [focal.item(), 0, size // 2],\n",
    "        [0, focal.item(), size // 2],\n",
    "        [0, 0, 1],\n",
    "    ], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a462e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2w = look_at(4, float_to_rad(1e-4), float_to_rad(0)).to(COMPUTE_DEVICE)\n",
    "img = model.render_image(200, 200, c2w, focal.to(COMPUTE_DEVICE))\n",
    "plt.imshow(img.cpu().clamp(0,1))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ff4337",
   "metadata": {},
   "source": [
    "# Point cloud using volume rendering depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4240684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (200, 200)\n",
    "thetas = [1e-4, 90, 90, 90, 90, 180 - 1e-4]\n",
    "phis = [0, 0, 90, 180, 270, 0]\n",
    "\n",
    "origins, directions = [], []\n",
    "for theta, phi in zip(thetas, phis):\n",
    "    o, d = create_rays(img_shape[0], img_shape[1], intrinsic(focal, 200), look_at(4, float_to_rad(theta), float_to_rad(phi)))\n",
    "    o, d = o.flatten(0, 1), d.flatten(0, 1)\n",
    "    origins.append(o)\n",
    "    directions.append(d)\n",
    "\n",
    "origins = torch.cat(origins, dim=0)\n",
    "directions = torch.cat(directions, dim=0)\n",
    "\n",
    "od_loader = DataLoader(TensorDataset(origins, directions), batch_size=2**11)\n",
    "\n",
    "coarse_rgbs, coarse_depths, fine_rgbs, fine_depths = [], [], [], []\n",
    "\n",
    "for o, d in od_loader:\n",
    "    with torch.no_grad():\n",
    "        cc, cd, fc, fd = model.compute_along_rays(o.to(COMPUTE_DEVICE), d.to(COMPUTE_DEVICE), coarse_samples=64, fine_samples=128)\n",
    "    coarse_rgbs.append(cc)\n",
    "    coarse_depths.append(cd)\n",
    "    fine_rgbs.append(fc)\n",
    "    fine_depths.append(fd)\n",
    "\n",
    "coarse_rgbs = torch.cat(coarse_rgbs, dim=0)\n",
    "coarse_depths = torch.cat(coarse_depths, dim=0)\n",
    "fine_rgbs = torch.cat(fine_rgbs, dim=0)\n",
    "fine_depths = torch.cat(fine_depths, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c8ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb, depth, acc, alpha, weights = render_rays(fine_rgbs, fine_depths, far=model.hparams.far)\n",
    "\n",
    "rescaled_acc = acc - acc.min()\n",
    "rescaled_acc /= rescaled_acc.max()\n",
    "\n",
    "rgba = torch.cat([rgb.cpu(), rescaled_acc.cpu()], dim=-1).clamp(0,1)\n",
    "images = rgba.reshape((-1,) + img_shape + (4,))\n",
    "image_grid = make_grid(images.permute(0, 3, 1, 2), 3).permute(1, 2, 0)\n",
    "\n",
    "depth_map = depth.reshape((-1,) + img_shape + (1,)).cpu()\n",
    "depth_map[depth_map <= model.hparams.near] = model.hparams.far\n",
    "depth_imgs = (depth_map.expand((-1, -1, -1, 3)) - model.hparams.near) / (model.hparams.far - model.hparams.near)\n",
    "depth_imgs = torch.cat([depth_imgs, torch.ones_like(depth_map)], dim=-1)\n",
    "depth_grid = make_grid(depth_imgs.permute(0, 3, 1, 2), 3).permute(1, 2, 0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(18, 6))\n",
    "ax.imshow(torch.cat([image_grid, depth_grid], dim=1))\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# torch.min(rescaled_acc), torch.max(rescaled_acc), torch.quantile(rescaled_acc, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c32aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def farthest_point_sampling(points, num_samples, return_indices=False):\n",
    "    sampled_indices = torch.zeros(num_samples, dtype=torch.long)\n",
    "    distances = torch.full((points.shape[0],), float('inf'))\n",
    "    \n",
    "    # Start with a random point\n",
    "    sampled_indices[0] = torch.randint(0, points.shape[0], (1,))\n",
    "    \n",
    "    for i in range(1, num_samples):\n",
    "        last_selected = points[sampled_indices[i-1]]\n",
    "        dist = torch.norm(points - last_selected, dim=1)\n",
    "        distances = torch.minimum(distances, dist)\n",
    "        sampled_indices[i] = torch.argmax(distances)\n",
    "    \n",
    "    if return_indices:\n",
    "        return points[sampled_indices], sampled_indices\n",
    "    \n",
    "    return points[sampled_indices]\n",
    "\n",
    "mask = (depth > model.hparams.near).cpu() & (rgba[..., -1] > 0.98)\n",
    "\n",
    "points = origins.cpu()[mask] + depth.unsqueeze(-1).cpu()[mask] * directions.cpu()[mask]\n",
    "points, sampled_indices = farthest_point_sampling(points, 10_000, True)\n",
    "colors = rgba[mask][sampled_indices]\n",
    "og = look_at(2, float_to_rad(70), float_to_rad(110))[:3, -1]\n",
    "sorting = torch.argsort(torch.norm(og - points, p=\"fro\", dim=-1), descending=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,8), subplot_kw={\"projection\": \"3d\"})\n",
    "for (x, y, z), color in zip(points[sorting], colors[sorting]):\n",
    "    ax.plot(x, y, z, linewidth=0, markersize=1, marker='o', c=color.tolist())\n",
    "ax.view_init(20, 110, 0)\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.set_zlim(-1, 1)\n",
    "\n",
    "points.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f15b8f",
   "metadata": {},
   "source": [
    "# Point cloud using density gradient based ray exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d0437c",
   "metadata": {},
   "source": [
    "## Ray and depth visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45d1dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (200, 200)\n",
    "theta, phi = 90, 0\n",
    "\n",
    "origins, directions = create_rays(img_shape[0], img_shape[1], intrinsic(focal, 200), look_at(4, float_to_rad(theta), float_to_rad(phi)))\n",
    "origins, directions = origins.flatten(0, 1), directions.flatten(0, 1)\n",
    "\n",
    "od_loader = DataLoader(TensorDataset(origins, directions), batch_size=2**11)\n",
    "\n",
    "coarse_rgbs, coarse_depths, fine_rgbs, fine_depths = [], [], [], []\n",
    "\n",
    "for o, d in od_loader:\n",
    "    with torch.no_grad():\n",
    "        cc, cd, fc, fd = model.compute_along_rays(o.to(COMPUTE_DEVICE), d.to(COMPUTE_DEVICE), coarse_samples=64, fine_samples=128)\n",
    "    coarse_rgbs.append(cc)\n",
    "    coarse_depths.append(cd)\n",
    "    fine_rgbs.append(fc)\n",
    "    fine_depths.append(fd)\n",
    "\n",
    "coarse_rgbs = torch.cat(coarse_rgbs, dim=0)\n",
    "coarse_depths = torch.cat(coarse_depths, dim=0)\n",
    "fine_rgbs = torch.cat(fine_rgbs, dim=0)\n",
    "fine_depths = torch.cat(fine_depths, dim=0)\n",
    "\n",
    "rgb, depth, acc, alpha, weights = render_rays(fine_rgbs, fine_depths, far=model.hparams.far)\n",
    "\n",
    "rescaled_acc = acc - acc.min()\n",
    "rescaled_acc /= rescaled_acc.max()\n",
    "\n",
    "rgba = torch.cat([rgb.cpu(), rescaled_acc.cpu()], dim=-1).clamp(0,1)\n",
    "plt.imshow(rgba.reshape(img_shape + (4,)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e355ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colored_line(ax, x, y, c, **kwargs):\n",
    "    if isinstance(c, torch.Tensor):\n",
    "        c = c.numpy()\n",
    "\n",
    "    for i in range(len(x)-1):\n",
    "        color = c[i] if (c[i] <= 0.9).any() else np.array([0.9, 0.9, 0.9])\n",
    "        ax.plot(x[i:i+2], y[i:i+2], color=color, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a420811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (200, 200)\n",
    "theta, phi = 90, 0\n",
    "idx = 85\n",
    "origins, directions = create_rays(img_shape[0], img_shape[1], intrinsic(focal, 200), look_at(4, float_to_rad(theta), float_to_rad(phi)))\n",
    "origin, direction = origins[idx:idx+1, idx], directions[idx:idx+1, idx]\n",
    "\n",
    "with torch.no_grad():\n",
    "    coarse_rgbs, coarse_depths, fine_rgbs, fine_depths = model.compute_along_rays(origin.to(COMPUTE_DEVICE), direction.to(COMPUTE_DEVICE), coarse_samples=256, fine_samples=256)\n",
    "rgb, depth, acc, alpha, weights = render_rays(fine_rgbs, fine_depths, far=model.hparams.far)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 4))\n",
    "ax.set_title(\"Colored coarse samples for full ray\")\n",
    "colored_line(ax, coarse_depths[0].cpu(), coarse_rgbs[0, ..., 3].cpu(), coarse_rgbs[0, ..., :3].cpu(), linewidth=4)\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 4))\n",
    "axs[0].set_title(\"Coarses\")\n",
    "colored_line(axs[0], coarse_depths[0].cpu(), coarse_rgbs[0, ..., 3].cpu(), coarse_rgbs[0, ..., :3].cpu())\n",
    "\n",
    "axs[1].set_title(\"Fines\")\n",
    "colored_line(axs[1], fine_depths[0].cpu(), fine_rgbs[0, ..., 3].cpu(), fine_rgbs[0, ..., :3].cpu())\n",
    "\n",
    "axs[2].set_title(\"Alphas\")\n",
    "axs[2].plot(fine_depths[0].cpu(), alpha[0].cpu())\n",
    "\n",
    "axs[3].set_title(\"Weights\")\n",
    "axs[3].plot(fine_depths[0].cpu(), weights[0].cpu())\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.axvline(depth.item(), color=\"red\")\n",
    "    ax.set_xlim(3.0, 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bde5f9b",
   "metadata": {},
   "source": [
    "## Gradient based ray exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae4df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ray_uniformally(origins: Tensor, directions: Tensor, near: float, far: float,\n",
    "                           num_samples: int) -> tuple[Tensor, Tensor, Tensor]:\n",
    "    device = origins.device\n",
    "    depths = torch.linspace(near, far, num_samples, dtype=torch.float32, device=device, requires_grad=True).expand(origins.shape[0], -1)\n",
    "    depths.retain_grad()\n",
    "    points = origins[..., None, :] + directions[..., None, :] * depths[..., :, None]\n",
    "    directions = directions[..., None, :].expand(points.shape)\n",
    "    return points, directions, depths\n",
    "\n",
    "origin, direction = origin.to(COMPUTE_DEVICE), direction.to(COMPUTE_DEVICE)\n",
    "points, point_dirs, depths = sample_ray_uniformally(origin, direction, model.hparams.near, model.hparams.far, num_samples=2**10)\n",
    "sigma = model.nerf(points, point_dirs, skip_colors=True)\n",
    "sigma.backward(torch.ones_like(sigma))\n",
    "sigma = sigma.detach()\n",
    "\n",
    "grads = depths.grad[0]\n",
    "display_grads = grads / torch.max(torch.abs(grads)) * torch.max(sigma)\n",
    "\n",
    "depths = depths.detach()\n",
    "plt.xlim(3.00, 3.4)\n",
    "plt.ylim(-5.0, torch.max(sigma).item())\n",
    "plt.plot(depths[0].cpu(), sigma[0, ..., 0].cpu(), label=\"sigma\")\n",
    "plt.plot(depths[0].cpu(), display_grads.cpu(), label=\"depth grad rescaled\")\n",
    "plt.xlabel(\"depth\")\n",
    "plt.plot(depths[0].cpu(), torch.zeros_like(depths[0].cpu()), label=\"zeroline\", color=\"red\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55aa684",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_limit = 5.0  # When sigma is larger than this, we use gradient ascent\n",
    "gamma = 2e-5  # Step size multiplier (analogous to learning rate for gradient descent)\n",
    "non_grad_step_size = 3e-2  # Step size when sigma is below limit\n",
    "grad_epsilon = 5e-2  # If the magnitude of the gradient falls below this, we consider the depth for the surface point to be found\n",
    "max_iters = 300  # Limit for iteration count\n",
    "\n",
    "depths = torch.full((max_iters,), torch.inf, dtype=torch.float32)\n",
    "sigmas = torch.full((max_iters,), torch.inf, dtype=torch.float32)\n",
    "grads = torch.full((max_iters,), torch.inf, dtype=torch.float32)\n",
    "\n",
    "verbose = True\n",
    "if verbose:\n",
    "    print(f\"{'depth':^8} | {'sigma':^9} | {'grad_step?':^10} | {'grad':^10} | {'step_size':^10}\")\n",
    "\n",
    "depth = torch.full((1,), model.hparams.near, dtype=torch.float32, requires_grad=True, device=COMPUTE_DEVICE)\n",
    "iters, stop = 0, False\n",
    "while not stop and depth < model.hparams.far and iters < max_iters:\n",
    "    # delta_sigma/delta_depth calculated\n",
    "    sigma = model.nerf(origin + depth * direction, direction, skip_colors=True)\n",
    "    depth.retain_grad()  # Needed to retain grad for non-leaf nodes in the computation graph\n",
    "    sigma.backward(torch.ones_like(sigma))  # Backward without target function\n",
    "\n",
    "    # fixed step size if sigma is below a limit (aka. empty space areas)\n",
    "    grad_step = (sigma > sigma_limit).all()\n",
    "    grad = depth.grad\n",
    "    step_size = grad * gamma\n",
    "    step_size[~grad_step] = non_grad_step_size\n",
    "\n",
    "    depths[iters] = depth.item()\n",
    "    sigmas[iters] = sigma.item()\n",
    "    grads[iters] = grad.item()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"{depth.item():8.6f} | {sigma.item():9.5f} | {str(grad_step.item()):<10} | {grad.item():10.5f} | {step_size.item():10.7f}\")\n",
    "    \n",
    "    # approximated local maximum specified by epsilon gradient\n",
    "    if grad.abs() < grad_epsilon:\n",
    "        stop = True \n",
    "\n",
    "    depth = depth + step_size\n",
    "    iters += 1\n",
    "\n",
    "mask = depths != torch.inf\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "ax.set_xlim(depths[mask].min() * 0.999, depths[mask].max() * 1.001)\n",
    "ax.set_ylim(-3, torch.max(sigmas[mask]) * 1.2)\n",
    "ax.set_title(f\"Local max found at depth {depths[mask][-1]:8.6f} after {iters:03d} iters\")\n",
    "ax.plot(depths[mask], sigmas[mask], label=\"sigma\", marker='o')\n",
    "ax.plot(depths[mask], grads[mask] / torch.max(grads[mask]), label=\"grad normalized\")\n",
    "ax.plot(depths[mask], torch.zeros_like(depths[mask]), label=\"zeroline\", linestyle='--', color=\"red\")\n",
    "ax.plot(depths[mask], torch.full_like(depths[mask], sigma_limit), label=\"sigma limit for grad step\", linestyle='--', color=\"purple\")\n",
    "ax.set_xlabel(\"depth\")\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
