{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c66edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow importing from src\n",
    "import sys\n",
    "sys.path.insert(0, '../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb3f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerf import LNeRF\n",
    "from utils.rays import create_rays, render_rays\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "COMPUTE_DEVICE = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    COMPUTE_DEVICE = torch.device('cuda:0')\n",
    "elif torch.mps.is_available():\n",
    "    COMPUTE_DEVICE = torch.device('mps')\n",
    "print(f\"{COMPUTE_DEVICE=}\")\n",
    "\n",
    "float_to_rad = lambda f: torch.deg2rad(torch.tensor(f, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631ac047",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62440382",
   "metadata": {},
   "source": [
    "## Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a05403",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LNeRF.load_from_checkpoint(\n",
    "    \"../lightning_logs/shurtape200x200/checkpoints/best_val_psnr_epoch=13.ckpt\",\n",
    "    map_location=COMPUTE_DEVICE,\n",
    "    hparams_file=\"../lightning_logs/shurtape200x200/hparams.yaml\"\n",
    ")\n",
    "focal = torch.tensor(model.hparams.focal, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b4e772",
   "metadata": {},
   "source": [
    "## Rendering parameter calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e6c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In accordance with mitsuba's conventions\n",
    "def look_at(radius: float, theta: Tensor, phi: Tensor, target: Tensor = torch.tensor([0,0,0], dtype=torch.float32)):\n",
    "    origin = torch.tensor([\n",
    "        radius * torch.sin(theta) * torch.cos(phi),\n",
    "        radius * torch.sin(theta) * torch.sin(phi),\n",
    "        radius * torch.cos(theta),\n",
    "    ])\n",
    "    \n",
    "    forward = F.normalize(origin - target, p=\"fro\", dim=0)\n",
    "    up = torch.tensor([0, 0, 1], dtype=torch.float32)\n",
    "    right = F.normalize(torch.cross(up, forward, dim=0), p=\"fro\", dim=0)\n",
    "    up = F.normalize(torch.cross(forward, right, dim=0), p=\"fro\", dim=0)\n",
    "\n",
    "    return torch.tensor([\n",
    "        [right[0], up[0], forward[0], origin[0]],\n",
    "        [right[1], up[1], forward[1], origin[1]],\n",
    "        [right[2], up[2], forward[2], origin[2]],\n",
    "        [0, 0, 0, 1],\n",
    "    ])\n",
    "\n",
    "look_at(4, float_to_rad(45), float_to_rad(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ad3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intrinsic(focal: Tensor, size: float):\n",
    "    return torch.tensor([\n",
    "        [focal.item(), 0, size // 2],\n",
    "        [0, focal.item(), size // 2],\n",
    "        [0, 0, 1],\n",
    "    ], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a462e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2w = look_at(4, float_to_rad(1e-4), float_to_rad(0)).to(COMPUTE_DEVICE)\n",
    "img = model.render_image(200, 200, c2w, focal.to(COMPUTE_DEVICE))\n",
    "plt.imshow(img.cpu().clamp(0,1))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ff4337",
   "metadata": {},
   "source": [
    "# Point cloud using volume rendering depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4240684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (200, 200)\n",
    "thetas = [1e-4, 90, 90, 90, 90, 180 - 1e-4]\n",
    "phis = [0, 0, 90, 180, 270, 0]\n",
    "\n",
    "origins, directions = [], []\n",
    "for theta, phi in zip(thetas, phis):\n",
    "    o, d = create_rays(img_shape[0], img_shape[1], intrinsic(focal, 200), look_at(4, float_to_rad(theta), float_to_rad(phi)))\n",
    "    o, d = o.flatten(0, 1), d.flatten(0, 1)\n",
    "    origins.append(o)\n",
    "    directions.append(d)\n",
    "\n",
    "origins = torch.cat(origins, dim=0)\n",
    "directions = torch.cat(directions, dim=0)\n",
    "\n",
    "od_loader = DataLoader(TensorDataset(origins, directions), batch_size=2**11)\n",
    "\n",
    "coarse_rgbs, coarse_depths, fine_rgbs, fine_depths = [], [], [], []\n",
    "\n",
    "for o, d in od_loader:\n",
    "    with torch.no_grad():\n",
    "        cc, cd, fc, fd = model.compute_along_rays(o.to(COMPUTE_DEVICE), d.to(COMPUTE_DEVICE), coarse_samples=64, fine_samples=128)\n",
    "    coarse_rgbs.append(cc)\n",
    "    coarse_depths.append(cd)\n",
    "    fine_rgbs.append(fc)\n",
    "    fine_depths.append(fd)\n",
    "\n",
    "coarse_rgbs = torch.cat(coarse_rgbs, dim=0)\n",
    "coarse_depths = torch.cat(coarse_depths, dim=0)\n",
    "fine_rgbs = torch.cat(fine_rgbs, dim=0)\n",
    "fine_depths = torch.cat(fine_depths, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c8ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb, depth, acc, alpha, weights = render_rays(fine_rgbs, fine_depths, far=model.hparams.far)\n",
    "\n",
    "rescaled_acc = acc - acc.min()\n",
    "rescaled_acc /= rescaled_acc.max()\n",
    "\n",
    "rgba = torch.cat([rgb.cpu(), rescaled_acc.cpu()], dim=-1).clamp(0,1)\n",
    "images = rgba.reshape((-1,) + img_shape + (4,))\n",
    "grid = make_grid(images.permute(0, 3, 1, 2), 3).permute(1, 2, 0)\n",
    "plt.imshow(grid)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# torch.min(rescaled_acc), torch.max(rescaled_acc), torch.quantile(rescaled_acc, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c32aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def farthest_point_sampling(points, num_samples):\n",
    "    sampled_indices = torch.zeros(num_samples, dtype=torch.long)\n",
    "    distances = torch.full((points.shape[0],), float('inf'))\n",
    "    \n",
    "    # Start with a random point\n",
    "    sampled_indices[0] = torch.randint(0, points.shape[0], (1,))\n",
    "    \n",
    "    for i in range(1, num_samples):\n",
    "        last_selected = points[sampled_indices[i-1]]\n",
    "        dist = torch.norm(points - last_selected, dim=1)\n",
    "        distances = torch.minimum(distances, dist)\n",
    "        sampled_indices[i] = torch.argmax(distances)\n",
    "    \n",
    "    return points[sampled_indices]\n",
    "\n",
    "mask = (depth > model.hparams.near).cpu() & (rgba[..., -1] > 0.98)\n",
    "\n",
    "colors = rgba[mask]\n",
    "points = origins.cpu()[mask] + depth.unsqueeze(-1).cpu()[mask] * directions.cpu()[mask]\n",
    "points = farthest_point_sampling(points, 10_000)\n",
    "og = look_at(2, float_to_rad(70), float_to_rad(110))[:3, -1]\n",
    "sorting = torch.argsort(torch.norm(og - points, p=\"fro\", dim=-1), descending=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,8), subplot_kw={\"projection\": \"3d\"})\n",
    "for (x, y, z), color in zip(points[sorting], colors[sorting]):\n",
    "    ax.plot(x, y, z, linewidth=0, markersize=1, marker='o', c=color.tolist())\n",
    "ax.view_init(20, 110, 0)\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.set_zlim(-1, 1)\n",
    "\n",
    "points.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f15b8f",
   "metadata": {},
   "source": [
    "# Point cloud using density gradient based ray exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d0437c",
   "metadata": {},
   "source": [
    "## Ray and depth visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45d1dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (200, 200)\n",
    "theta, phi = 90, 0\n",
    "\n",
    "origins, directions = create_rays(img_shape[0], img_shape[1], intrinsic(focal, 200), look_at(4, float_to_rad(theta), float_to_rad(phi)))\n",
    "origins, directions = origins.flatten(0, 1), directions.flatten(0, 1)\n",
    "\n",
    "od_loader = DataLoader(TensorDataset(origins, directions), batch_size=2**11)\n",
    "\n",
    "coarse_rgbs, coarse_depths, fine_rgbs, fine_depths = [], [], [], []\n",
    "\n",
    "for o, d in od_loader:\n",
    "    with torch.no_grad():\n",
    "        cc, cd, fc, fd = model.compute_along_rays(o.to(COMPUTE_DEVICE), d.to(COMPUTE_DEVICE), coarse_samples=64, fine_samples=128)\n",
    "    coarse_rgbs.append(cc)\n",
    "    coarse_depths.append(cd)\n",
    "    fine_rgbs.append(fc)\n",
    "    fine_depths.append(fd)\n",
    "\n",
    "coarse_rgbs = torch.cat(coarse_rgbs, dim=0)\n",
    "coarse_depths = torch.cat(coarse_depths, dim=0)\n",
    "fine_rgbs = torch.cat(fine_rgbs, dim=0)\n",
    "fine_depths = torch.cat(fine_depths, dim=0)\n",
    "\n",
    "rgb, depth, acc, alpha, weights = render_rays(fine_rgbs, fine_depths, far=model.hparams.far)\n",
    "\n",
    "rescaled_acc = acc - acc.min()\n",
    "rescaled_acc /= rescaled_acc.max()\n",
    "\n",
    "rgba = torch.cat([rgb.cpu(), rescaled_acc.cpu()], dim=-1).clamp(0,1)\n",
    "plt.imshow(rgba.reshape(img_shape + (4,)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a420811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (200, 200)\n",
    "theta, phi = 90, 0\n",
    "origins, directions = create_rays(img_shape[0], img_shape[1], intrinsic(focal, 200), look_at(4, float_to_rad(theta), float_to_rad(phi)))\n",
    "origin, direction = origins[80:81, 80], directions[80:81, 80]\n",
    "\n",
    "with torch.no_grad():\n",
    "    coarse_rgbs, coarse_depths, fine_rgbs, fine_depths = model.compute_along_rays(origin.to(COMPUTE_DEVICE), direction.to(COMPUTE_DEVICE), coarse_samples=256, fine_samples=256)\n",
    "rgb, depth, acc, alpha, weights = render_rays(fine_rgbs, fine_depths, far=model.hparams.far)\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 4))\n",
    "\n",
    "axs[0].set_title(\"Coarses\")\n",
    "axs[0].plot(coarse_depths[0].cpu(), coarse_rgbs[0, ..., 3].cpu())\n",
    "\n",
    "axs[1].set_title(\"Fines\")\n",
    "axs[1].plot(fine_depths[0].cpu(), fine_rgbs[0, ..., 3].cpu())\n",
    "\n",
    "axs[2].set_title(\"Alphas\")\n",
    "axs[2].plot(fine_depths[0].cpu(), alpha[0].cpu())\n",
    "\n",
    "axs[3].set_title(\"Weights\")\n",
    "axs[3].plot(fine_depths[0].cpu(), weights[0].cpu())\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.axvline(depth.item(), color=\"red\")\n",
    "    ax.set_xlim(3.0, 3.5)\n",
    "\n",
    "print(depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bde5f9b",
   "metadata": {},
   "source": [
    "## Gradient based ray exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ea75c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.linspace(-3.0, 3.0, 1000, requires_grad=True)\n",
    "y = x ** 2\n",
    "y.backward(torch.ones_like(x))\n",
    "\n",
    "plt.plot(x.detach(), y.detach(), label=\"x^2\")\n",
    "plt.plot(x.detach(), x.grad, label=\"dx/dy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae4df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ray_uniformally(origins: Tensor, directions: Tensor, near: float, far: float,\n",
    "                           num_samples: int) -> tuple[Tensor, Tensor, Tensor]:\n",
    "    device = origins.device\n",
    "    depths = torch.linspace(near, far, num_samples, dtype=torch.float32, device=device, requires_grad=True).expand(origins.shape[0], -1)\n",
    "    depths.retain_grad()\n",
    "    points = origins[..., None, :] + directions[..., None, :] * depths[..., :, None]\n",
    "    directions = directions[..., None, :].expand(points.shape)\n",
    "    return points, directions, depths\n",
    "\n",
    "points, point_dirs, depths = sample_ray_uniformally(origin.to(COMPUTE_DEVICE), direction.to(COMPUTE_DEVICE), model.hparams.near, model.hparams.far, num_samples=1024)\n",
    "sigma = model.nerf(points, point_dirs, skip_colors=True)\n",
    "sigma.backward(torch.ones_like(sigma))\n",
    "sigma = sigma.detach()\n",
    "\n",
    "grads = depths.grad[0]\n",
    "rescaled_grads = grads / torch.max(torch.abs(grads)) * torch.max(sigma)\n",
    "\n",
    "depths = depths.detach()\n",
    "plt.xlim(3.00, 3.4)\n",
    "plt.ylim(-5.0, torch.max(sigma).item())\n",
    "plt.plot(depths[0].cpu(), sigma[0, ..., 0].cpu(), label=\"sigma\")\n",
    "plt.plot(depths[0].cpu(), rescaled_grads.cpu(), label=\"depth grad\")\n",
    "plt.plot(depths[0].cpu(), torch.zeros_like(depths[0].cpu()), label=\"zeroline\", color=\"red\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
