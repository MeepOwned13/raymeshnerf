{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c66edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow importing from src\n",
    "import sys\n",
    "sys.path.insert(0, '../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb3f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerf import LNeRF\n",
    "from utils.rays import create_rays, render_rays\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "COMPUTE_DEVICE = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    COMPUTE_DEVICE = torch.device('cuda:0')\n",
    "elif torch.mps.is_available():\n",
    "    COMPUTE_DEVICE = torch.device('mps')\n",
    "print(f\"{COMPUTE_DEVICE=}\")\n",
    "\n",
    "float_to_rad = lambda f: torch.deg2rad(torch.tensor(f, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a05403",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LNeRF.load_from_checkpoint(\n",
    "    \"../lightning_logs/shurtape200x200/checkpoints/best_val_psnr_epoch=13.ckpt\",\n",
    "    map_location=COMPUTE_DEVICE,\n",
    "    hparams_file=\"../lightning_logs/shurtape200x200/hparams.yaml\"\n",
    ")\n",
    "focal = torch.tensor(model.hparams.focal, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e6c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In accordance with mitsuba's conventions\n",
    "def look_at(radius: float, theta: Tensor, phi: Tensor, target: Tensor = torch.tensor([0,0,0], dtype=torch.float32)):\n",
    "    origin = torch.tensor([\n",
    "        radius * torch.sin(theta) * torch.cos(phi),\n",
    "        radius * torch.sin(theta) * torch.sin(phi),\n",
    "        radius * torch.cos(theta),\n",
    "    ])\n",
    "    \n",
    "    forward = F.normalize(origin - target, p=\"fro\", dim=0)\n",
    "    up = torch.tensor([0, 0, 1], dtype=torch.float32)\n",
    "    right = F.normalize(torch.cross(up, forward, dim=0), p=\"fro\", dim=0)\n",
    "    up = F.normalize(torch.cross(forward, right, dim=0), p=\"fro\", dim=0)\n",
    "\n",
    "    return torch.tensor([\n",
    "        [right[0], up[0], forward[0], origin[0]],\n",
    "        [right[1], up[1], forward[1], origin[1]],\n",
    "        [right[2], up[2], forward[2], origin[2]],\n",
    "        [0, 0, 0, 1],\n",
    "    ])\n",
    "\n",
    "look_at(4, float_to_rad(45), float_to_rad(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ad3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intrinsic(focal: Tensor, size: float):\n",
    "    return torch.tensor([\n",
    "        [focal.item(), 0, size // 2],\n",
    "        [0, focal.item(), size // 2],\n",
    "        [0, 0, 1],\n",
    "    ], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a462e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2w = look_at(4, float_to_rad(1e-4), float_to_rad(0)).to(COMPUTE_DEVICE)\n",
    "img = model.render_image(200, 200, c2w, focal.to(COMPUTE_DEVICE))\n",
    "plt.imshow(img.cpu().clamp(0,1))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4240684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (200, 200)\n",
    "thetas = [1e-4, 90, 90, 90, 90, 180 - 1e-4]\n",
    "phis = [0, 0, 90, 180, 270, 0]\n",
    "\n",
    "origins, directions = [], []\n",
    "for theta, phi in zip(thetas, phis):\n",
    "    o, d = create_rays(img_shape[0], img_shape[1], intrinsic(focal, 200), look_at(4, float_to_rad(theta), float_to_rad(phi)))\n",
    "    o, d = o.flatten(0, 1), d.flatten(0, 1)\n",
    "    origins.append(o)\n",
    "    directions.append(d)\n",
    "\n",
    "origins = torch.cat(origins, dim=0)\n",
    "directions = torch.cat(directions, dim=0)\n",
    "\n",
    "od_loader = DataLoader(TensorDataset(origins, directions), batch_size=2**11)\n",
    "\n",
    "coarse_rgbs, coarse_depths, fine_rgbs, fine_depths = [], [], [], []\n",
    "\n",
    "for o, d in od_loader:\n",
    "    with torch.no_grad():\n",
    "        cc, cd, fc, fd = model.compute_along_rays(o.to(COMPUTE_DEVICE), d.to(COMPUTE_DEVICE), coarse_samples=64, fine_samples=128)\n",
    "    coarse_rgbs.append(cc)\n",
    "    coarse_depths.append(cd)\n",
    "    fine_rgbs.append(fc)\n",
    "    fine_depths.append(fd)\n",
    "\n",
    "coarse_rgbs = torch.cat(coarse_rgbs, dim=0)\n",
    "coarse_depths = torch.cat(coarse_depths, dim=0)\n",
    "fine_rgbs = torch.cat(fine_rgbs, dim=0)\n",
    "fine_depths = torch.cat(fine_depths, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c8ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb, depth, acc, alpha, weights = render_rays(fine_rgbs, fine_depths, far=model.hparams.far)\n",
    "\n",
    "rescaled_acc = acc - acc.min()\n",
    "rescaled_acc /= rescaled_acc.max()\n",
    "\n",
    "rgba = torch.cat([rgb.cpu(), rescaled_acc.cpu()], dim=-1).clamp(0,1)\n",
    "images = rgba.reshape((-1,) + img_shape + (4,))\n",
    "for img in images:\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# torch.min(rescaled_acc), torch.max(rescaled_acc), torch.quantile(rescaled_acc, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c32aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (depth > model.hparams.near).cpu() & (rgba[..., -1] > 0.98)\n",
    "\n",
    "colors = rgba[mask]\n",
    "points = origins.cpu()[mask] + depth.unsqueeze(-1).cpu()[mask] * directions.cpu()[mask]\n",
    "og = look_at(2, float_to_rad(70), float_to_rad(110))[:3, -1]\n",
    "sorting = torch.argsort(torch.norm(og - points, p=\"fro\", dim=-1), descending=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,8), subplot_kw={\"projection\": \"3d\"})\n",
    "for (x, y, z), color in zip(points[sorting], colors[sorting]):\n",
    "    ax.plot(x, y, z, linewidth=0, markersize=1, marker='o', c=color.tolist())\n",
    "ax.view_init(20, 110, 0)\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.set_zlim(-1, 1)\n",
    "\n",
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a420811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "idx = 40 * img_shape[0] + 40\n",
    "\n",
    "axs[0,0].set_title(\"Coarses\")\n",
    "axs[0,0].plot(coarse_depths.cpu()[idx, ...], coarse_rgbs.cpu()[idx, ..., 3])\n",
    "\n",
    "axs[0,1].set_title(\"Fines\")\n",
    "axs[0,1].plot(fine_depths.cpu()[idx, ...], fine_rgbs.cpu()[idx, ..., 3])\n",
    "\n",
    "axs[1,0].set_title(\"Alphas\")\n",
    "axs[1,0].plot(fine_depths.cpu()[idx, ...], alpha.cpu()[idx, ...])\n",
    "\n",
    "axs[1,1].set_title(\"Weights\")\n",
    "axs[1,1].plot(fine_depths.cpu()[idx, ...], weights.cpu()[idx, ...])\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.axvline(depth[idx].item(), color=\"red\")\n",
    "    ax.set_xlim(3, 3.5)\n",
    "\n",
    "print(depth[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
